## Цели работы:
построить модель машинного обучения которая сможет находить токсичные комментарии на основе уже имеющихся и размеченных и отправлять их на ручную модерацию

## этапы работы:
* загрузить данные
* удалить из сообщений слова не несущие полезной нагрузки
* лемматизировать слова в сообщениях
* перевести сообщения в векторный вид
* обучить несколько моделей
* выбрать наилучшую, проверить что метрика качества f1 на валиадационной и тестовой выборках у нее не меньше 0.75


## Выводы
  Мы построили модель машинного обучения которая с достаточной точностью может находить токсичные комментарии на основе уже имеющихся и размеченных.

В ходе работы мы
* обработали сообщения: очистив их от не несущих пользу слов, лемматизировали, привели в векторный вид
* обучили несколько моделей
* под необходимые критерии подошла модель CatBoost
* удостоверились что требования выполняются и на тестовой выборке

Векторизацией слов с помощью TF-IDF удалось достичь необходимого бейслайна. Особенностью метода в данном случае можно выделить то что точность предсказаний растет с ростом выборки (впрочем как и время расчетов). Дополнительный прирост точности прогнозов также можно было получить обьединив тренировочную и валидационную выбоки
